{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/donna/Documents/sem3/csci599/project/method2/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import binvox_rw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading VGG16 Model ...\n",
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "from lib.tfmodels import vgg16\n",
    "\n",
    "vgg16.maybe_download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_to_rgb(image):\n",
    "    w, h = image.shape\n",
    "    res = np.empty((w, h, 3), dtype=np.uint8)\n",
    "    res[:, :, 0] = image\n",
    "    res[:, :, 1] = image\n",
    "    res[:, :, 2] = image\n",
    "    return res\n",
    "\n",
    "def color_from_2d(voxel, face, color):\n",
    "    face_mask = np.where(face > -1)\n",
    "    voxel[(face[face_mask],) + face_mask] = color[face_mask]\n",
    "\n",
    "def voxel_to_2d(voxel):\n",
    "    p1, p2, p3 = voxel, voxel.transpose((1,0,2)), voxel.transpose((2,1,0))\n",
    "    p4, p5, p6 = np.flip(p1, axis=0), np.flip(p2, axis=0), np.flip(p3, axis=0)\n",
    "    \n",
    "    p = np.stack((p1, p2, p3, p4, p5, p6))\n",
    "    faces = np.where(p.any(1), p.argmax(1), -1)\n",
    "    faces_mask = np.where(faces > -1)\n",
    "    \n",
    "    colors = np.ones(faces.shape + (3,))\n",
    "    vox_size = voxel.shape[0] \n",
    "    fzyx = (faces[faces_mask],) + (faces_mask[1:])\n",
    "    colors[faces_mask] = np.stack(fzyx, axis=-1) / vox_size * 255.\n",
    "    \n",
    "    return faces.expand_dims(axis=-1), colors\n",
    "\n",
    "def generate_voxel_colors(colors, faces, shape):\n",
    "    voxel_colors = np.zeros(shape + (3,))\n",
    "    views = [[0,1,2,3], [1,0,2,3], [2,0,1,3]]\n",
    "\n",
    "    for i, v in enumerate(views):\n",
    "        voxel_colors = voxel_colors.transpose(v)\n",
    "        color_from_2d(voxel_colors, faces[i], colors[i])\n",
    "        voxel_colors = np.flip(voxel_colors, axis=0)\n",
    "        color_from_2d(voxel_colors, faces[i+3], colors[i+3])\n",
    "        voxel_colors = np.flip(voxel_colors, axis=0)\n",
    "    \n",
    "    return voxel_colors.transpose((2,1,0,3))\n",
    "\n",
    "def load_voxel(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        model = binvox_rw.read_as_3d_array(f)\n",
    "        \n",
    "    return model.data\n",
    "\n",
    "def load_image(filename, max_size=None):\n",
    "    image = PIL.Image.open(filename)\n",
    "\n",
    "    if max_size is not None:\n",
    "        # Calculate the appropriate rescale-factor for\n",
    "        # ensuring a max height and width, while keeping\n",
    "        # the proportion between them.\n",
    "        factor = max_size / np.max(image.size)\n",
    "    \n",
    "        # Scale the image's height and width.\n",
    "        size = np.array(image.size) * factor\n",
    "\n",
    "        # The size is now floating-point because it was scaled.\n",
    "        # But PIL requires the size to be integers.\n",
    "        size = size.astype(int)\n",
    "\n",
    "        # Resize the image.\n",
    "        image = np.asarray(image.resize(size, PIL.Image.LANCZOS), dtype=np.float32)\n",
    "\n",
    "        if len(image.shape) == 2:\n",
    "            image = gray_to_rgb(image)\n",
    "\n",
    "    # Convert to numpy floating-point array.\n",
    "    return np.asarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_from_2d(voxel, face, color):\n",
    "#     face_mask = np.where(face > -1)\n",
    "#     voxel[(face[face_mask],) + face_mask] = color[face_mask]\n",
    "    \n",
    "    coords_face = np.where(face[:,:,0])\n",
    "    coords_vox = tuple(face[coords_face][:,1:].astype(int).T)\n",
    "    \n",
    "    print(face.shape, color.shape)\n",
    "    print(\"voxel.shape\", voxel.shape)\n",
    "    print(\"color.shape\", color.shape)\n",
    "    print(\"coords_face.shape\", np.shape(coords_face))\n",
    "    print(\"coords_vox.shape\", np.shape(coords_vox))\n",
    "    voxel[coords_vox] = color[coords_face]\n",
    "\n",
    "def voxel_to_2d(voxel, windows):\n",
    "    print(\"voxel_2d\")\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    voxel = np.asarray(voxel, dtype=np.float32)\n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    for window in windows:\n",
    "        voxel_curr = np.pad(voxel, (window-1)//2, 'constant', constant_values=0.)\n",
    "        voxel_curr = np.expand_dims(voxel_curr, axis= 0)\n",
    "        voxel_curr = np.expand_dims(voxel_curr, axis= 4)\n",
    "        \n",
    "        voxel_pl = tf.placeholder(tf.float32, shape=voxel_curr.shape)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            with tf.device('/cpu:0'):\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                output.append(sess.run(\n",
    "                    tf.nn.avg_pool3d(voxel_pl, [1, window, window, window, 1], [1,1,1,1,1], 'VALID'), \n",
    "                    feed_dict={voxel_pl: voxel_curr})[0])\n",
    "\n",
    "    output = np.concatenate(output, axis=3)            \n",
    "    \n",
    "    faces = get_faces(voxel)            \n",
    "    \n",
    "    faces_mask = np.where(faces > -1)\n",
    "    \n",
    "    p_colors = get_color_faces(output)\n",
    "    colors = np.ones(faces.shape + (3,))\n",
    "    vox_size = voxel.shape[0] \n",
    "    print(colors.shape)\n",
    "    print(p_colors.shape)\n",
    "    colors[faces_mask] = p_colors[faces_mask]\n",
    "\n",
    "    return np.expand_dims(faces, axis=3), colors\n",
    "\n",
    "def get_faces(voxel):\n",
    "    p1, p2, p3 = voxel, voxel.transpose((1,0,2)), voxel.transpose((2,1,0))\n",
    "    p4, p5, p6 = np.flip(p1, axis=0), np.flip(p2, axis=0), np.flip(p3, axis=0)\n",
    "    \n",
    "    p = np.stack((p1, p2, p3, p4, p5, p6))\n",
    "    \n",
    "    return np.where(p.any(1), p.argmax(1), -1)\n",
    "\n",
    "def get_color_faces(voxel):\n",
    "    p1, p2, p3 = voxel, voxel.transpose((1,0,2,3)), voxel.transpose((2,1,0,3))\n",
    "    p4, p5, p6 = np.flip(p1, axis=0), np.flip(p2, axis=0), np.flip(p3, axis=0)\n",
    "    \n",
    "    p = np.stack((p1, p2, p3, p4, p5, p6))\n",
    "\n",
    "    return np.where(p.any(1), p.argmax(1), -1)\n",
    "\n",
    "def voxel_to_2d_old(voxel):\n",
    "    tuple_voxels = np.zeros(voxel.shape + (4,))\n",
    "    \n",
    "    for x in range(voxel.shape[0]):\n",
    "        for y in range(voxel.shape[1]):\n",
    "            for z in range(voxel.shape[2]):\n",
    "                tuple_voxels[x, y, z] = [voxel[x, y, z], x, y, z]\n",
    "    p1, p2, p3 = tuple_voxels, tuple_voxels.transpose((1,0,2,3)), tuple_voxels.transpose((2,1,0,3))\n",
    "    p4, p5, p6 = np.flip(p1, axis=0), np.flip(p2, axis=0), np.flip(p3, axis=0)\n",
    "    \n",
    "    p = np.stack((p1, p2, p3, p4, p5, p6))\n",
    "    argmax_vals = np.argmax(p[:,:,:,:,0], axis =1)\n",
    "    faces_second = np.ones((p.shape[0],p.shape[2], p.shape[3], p.shape[4])) * -1\n",
    "    \n",
    "    for x in range(argmax_vals.shape[1]):\n",
    "        for y in range(argmax_vals.shape[2]):\n",
    "            for face in range(argmax_vals.shape[0]):\n",
    "                faces_second[face,y,x] = p[face,argmax_vals[face,y, x], y, x]\n",
    "            \n",
    "    colors = np.ones((faces_second.shape[0], faces_second.shape[1],faces_second.shape[2])  + (3,)) * 255.        \n",
    "    vox_size = voxel.shape[0]\n",
    "    \n",
    "    colors[:, :, :,0] = faces_second[:, :, :, 0]  * faces_second[:, :, :,2]/ vox_size * 255.\n",
    "    colors[:, :, :,1] = faces_second[:, :, :, 0] * faces_second[:, :, :,2]/ vox_size * 255.\n",
    "    colors[:, :, :,2] = faces_second[:, :, :, 0] * faces_second[:, :, :,3]/ vox_size *255.\n",
    "    \n",
    "    return faces_second, colors\n",
    "\n",
    "def generate_voxel_colors(colors, faces, shape):\n",
    "#     voxel_colors = np.zeros(shape + (3,))\n",
    "#     for i in range(len(faces)):\n",
    "#         color_from_2d(voxel_colors, faces[i], colors[i])\n",
    "#     return voxel_colors\n",
    "\n",
    "    voxel_colors = np.zeros(shape + (3,))\n",
    "    views = [[0,1,2,3], [1,0,2,3], [2,0,1,3]]\n",
    "\n",
    "    for i, v in enumerate(views):\n",
    "        voxel_colors = voxel_colors.transpose(v)\n",
    "        color_from_2d(voxel_colors, faces[i], colors[i])\n",
    "        voxel_colors = np.flip(voxel_colors, axis=0)\n",
    "        color_from_2d(voxel_colors, faces[i+3], colors[i+3])\n",
    "        voxel_colors = np.flip(voxel_colors, axis=0)\n",
    "    \n",
    "    return voxel_colors.transpose((2,1,0,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(image, filename):\n",
    "    # Ensure the pixel-values are between 0 and 255.\n",
    "    image = np.clip(image, 0.0, 255.0)\n",
    "    \n",
    "    # Convert to bytes.\n",
    "    image = image.astype(np.uint8)\n",
    "    \n",
    "    # Write the image-file in jpeg-format.\n",
    "    with open(filename, 'wb') as file:\n",
    "        PIL.Image.fromarray(image).save(file, 'jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_big(image):\n",
    "    # Ensure the pixel-values are between 0 and 255.\n",
    "    image = np.clip(image, 0.0, 255.0)\n",
    "\n",
    "    # Convert pixels to bytes.\n",
    "    image = image.astype(np.uint8)\n",
    "\n",
    "    # Convert to a PIL-image and display it.\n",
    "    display(PIL.Image.fromarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(content_image, style_image, mixed_image):\n",
    "    # Create figure with sub-plots.\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(10, 10))\n",
    "\n",
    "    # Adjust vertical spacing.\n",
    "    fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "    # Use interpolation to smooth pixels?\n",
    "    smooth = False\n",
    "    \n",
    "    # Interpolation type.\n",
    "    if smooth:\n",
    "        interpolation = 'sinc'\n",
    "    else:\n",
    "        interpolation = 'nearest'\n",
    "\n",
    "    # Plot the content-image.\n",
    "    # Note that the pixel-values are normalized to\n",
    "    # the [0.0, 1.0] range by dividing with 255.\n",
    "    ax = axes.flat[0]\n",
    "    ax.imshow(content_image / 255.0, interpolation=interpolation)\n",
    "    ax.set_xlabel(\"Content\")\n",
    "\n",
    "    # Plot the mixed-image.\n",
    "    ax = axes.flat[1]\n",
    "    ax.imshow(mixed_image / 255.0, interpolation=interpolation)\n",
    "    ax.set_xlabel(\"Mixed\")\n",
    "\n",
    "    # Plot the style-image\n",
    "    ax = axes.flat[2]\n",
    "    ax.imshow(style_image / 255.0, interpolation=interpolation)\n",
    "    ax.set_xlabel(\"Style\")\n",
    "\n",
    "    # Remove ticks from all the plots.\n",
    "    for ax in axes.flat:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()\n",
    "    \n",
    "def plot_2d_faces(face_colors):\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(10, 10))\n",
    "    fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "    for i, face in enumerate(face_colors):\n",
    "        ax = axes.flat[i]\n",
    "        ax.imshow(face / 255.0)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def plot_3d_voxel(voxel, colors):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.voxels(voxel, facecolors=colors / 255.0)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(a, b):\n",
    "    return tf.reduce_mean(tf.square(a - b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_content_loss(session, model, content_image, layer_ids):\n",
    "    \"\"\"\n",
    "    Create the loss-function for the content-image.\n",
    "    \n",
    "    Parameters:\n",
    "    session: An open TensorFlow session for running the model's graph.\n",
    "    model: The model, e.g. an instance of the VGG16-class.\n",
    "    content_image: Numpy float array with the content-image.\n",
    "    layer_ids: List of integer id's for the layers to use in the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a feed-dict with the content-image.\n",
    "    feed_dict = model.create_feed_dict(image=content_image)\n",
    "\n",
    "    # Get references to the tensors for the given layers.\n",
    "    layers = model.get_layer_tensors(layer_ids)\n",
    "\n",
    "    # Calculate the output values of those layers when\n",
    "    # feeding the content-image to the model.\n",
    "    values = session.run(layers, feed_dict=feed_dict)\n",
    "\n",
    "    # Set the model's graph as the default so we can add\n",
    "    # computational nodes to it. It is not always clear\n",
    "    # when this is necessary in TensorFlow, but if you\n",
    "    # want to re-use this code then it may be necessary.\n",
    "    with model.graph.as_default():\n",
    "        # Initialize an empty list of loss-functions.\n",
    "        layer_losses = []\n",
    "    \n",
    "        # For each layer and its corresponding values\n",
    "        # for the content-image.\n",
    "        for value, layer in zip(values, layers):\n",
    "            # These are the values that are calculated\n",
    "            # for this layer in the model when inputting\n",
    "            # the content-image. Wrap it to ensure it\n",
    "            # is a const - although this may be done\n",
    "            # automatically by TensorFlow.\n",
    "            value_const = tf.constant(value)\n",
    "\n",
    "            # The loss-function for this layer is the\n",
    "            # Mean Squared Error between the layer-values\n",
    "            # when inputting the content- and mixed-images.\n",
    "            # Note that the mixed-image is not calculated\n",
    "            # yet, we are merely creating the operations\n",
    "            # for calculating the MSE between those two.\n",
    "            loss = mean_squared_error(layer, value_const)\n",
    "\n",
    "            # Add the loss-function for this layer to the\n",
    "            # list of loss-functions.\n",
    "            layer_losses.append(loss)\n",
    "            \n",
    "        # The combined loss for all layers is just the average.\n",
    "        # The loss-functions could be weighted differently for\n",
    "        # each layer. You can try it and see what happens.\n",
    "        total_loss = tf.reduce_mean(layer_losses)\n",
    "        \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(tensor):\n",
    "    shape = tensor.get_shape()\n",
    "    \n",
    "    # Get the number of feature channels for the input tensor,\n",
    "    # which is assumed to be from a convolutional layer with 4-dim.\n",
    "    num_channels = int(shape[3])\n",
    "\n",
    "    # Reshape the tensor so it is a 2-dim matrix. This essentially\n",
    "    # flattens the contents of each feature-channel.\n",
    "    matrix = tf.reshape(tensor, shape=[-1, num_channels])\n",
    "    \n",
    "    # Calculate the Gram-matrix as the matrix-product of\n",
    "    # the 2-dim matrix with itself. This calculates the\n",
    "    # dot-products of all combinations of the feature-channels.\n",
    "    gram = tf.matmul(tf.transpose(matrix), matrix)\n",
    "\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_style_loss(session, model, style_image, layer_ids):\n",
    "    \"\"\"\n",
    "    Create the loss-function for the style-image.\n",
    "    \n",
    "    Parameters:\n",
    "    session: An open TensorFlow session for running the model's graph.\n",
    "    model: The model, e.g. an instance of the VGG16-class.\n",
    "    style_image: Numpy float array with the style-image.\n",
    "    layer_ids: List of integer id's for the layers to use in the model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a feed-dict with the style-image.\n",
    "    feed_dict = model.create_feed_dict(image=style_image)\n",
    "\n",
    "    # Get references to the tensors for the given layers.\n",
    "    layers = model.get_layer_tensors(layer_ids)\n",
    "\n",
    "    # Set the model's graph as the default so we can add\n",
    "    # computational nodes to it. It is not always clear\n",
    "    # when this is necessary in TensorFlow, but if you\n",
    "    # want to re-use this code then it may be necessary.\n",
    "    with model.graph.as_default():\n",
    "        # Construct the TensorFlow-operations for calculating\n",
    "        # the Gram-matrices for each of the layers.\n",
    "        gram_layers = [gram_matrix(layer) for layer in layers]\n",
    "\n",
    "        # Calculate the values of those Gram-matrices when\n",
    "        # feeding the style-image to the model.\n",
    "        values = session.run(gram_layers, feed_dict=feed_dict)\n",
    "\n",
    "        # Initialize an empty list of loss-functions.\n",
    "        layer_losses = []\n",
    "        \n",
    "        # For each Gram-matrix layer and its corresponding values.\n",
    "        for value, gram_layer in zip(values, gram_layers):\n",
    "            # These are the Gram-matrix values that are calculated\n",
    "            # for this layer in the model when inputting the\n",
    "            # style-image. Wrap it to ensure it is a const,\n",
    "            # although this may be done automatically by TensorFlow.\n",
    "            value_const = tf.constant(value)\n",
    "\n",
    "            # The loss-function for this layer is the\n",
    "            # Mean Squared Error between the Gram-matrix values\n",
    "            # for the content- and mixed-images.\n",
    "            # Note that the mixed-image is not calculated\n",
    "            # yet, we are merely creating the operations\n",
    "            # for calculating the MSE between those two.\n",
    "            loss = mean_squared_error(gram_layer, value_const)\n",
    "\n",
    "            # Add the loss-function for this layer to the\n",
    "            # list of loss-functions.\n",
    "            layer_losses.append(loss)\n",
    "\n",
    "        # The combined loss for all layers is just the average.\n",
    "        # The loss-functions could be weighted differently for\n",
    "        # each layer. You can try it and see what happens.\n",
    "        total_loss = tf.reduce_mean(layer_losses)\n",
    "        \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_denoise_loss(model):\n",
    "    loss = tf.reduce_sum(tf.abs(model.input[:,1:,:,:] - model.input[:,:-1,:,:])) + \\\n",
    "           tf.reduce_sum(tf.abs(model.input[:,:,1:,:] - model.input[:,:,:-1,:]))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_transfer(content_image, style_image,\n",
    "                   content_layer_ids, style_layer_ids,\n",
    "                   weight_content=1.5, weight_style=10.0,\n",
    "                   weight_denoise=0.3,\n",
    "                   num_iterations=120, step_size=10.0):\n",
    "    \"\"\"\n",
    "    Use gradient descent to find an image that minimizes the\n",
    "    loss-functions of the content-layers and style-layers. This\n",
    "    should result in a mixed-image that resembles the contours\n",
    "    of the content-image, and resembles the colours and textures\n",
    "    of the style-image.\n",
    "    \n",
    "    Parameters:\n",
    "    content_image: Numpy 3-dim float-array with the content-image.\n",
    "    style_image: Numpy 3-dim float-array with the style-image.\n",
    "    content_layer_ids: List of integers identifying the content-layers.\n",
    "    style_layer_ids: List of integers identifying the style-layers.\n",
    "    weight_content: Weight for the content-loss-function.\n",
    "    weight_style: Weight for the style-loss-function.\n",
    "    weight_denoise: Weight for the denoising-loss-function.\n",
    "    num_iterations: Number of optimization iterations to perform.\n",
    "    step_size: Step-size for the gradient in each iteration.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an instance of the VGG16-model. This is done\n",
    "    # in each call of this function, because we will add\n",
    "    # operations to the graph so it can grow very large\n",
    "    # and run out of RAM if we keep using the same instance.\n",
    "    model = vgg16.VGG16()\n",
    "\n",
    "    # Create a TensorFlow-session.\n",
    "    session = tf.InteractiveSession(graph=model.graph)\n",
    "\n",
    "    # Print the names of the content-layers.\n",
    "    print(\"Content layers:\")\n",
    "    print(model.get_layer_names(content_layer_ids))\n",
    "    print()\n",
    "\n",
    "    # Print the names of the style-layers.\n",
    "    print(\"Style layers:\")\n",
    "    print(model.get_layer_names(style_layer_ids))\n",
    "    print()\n",
    "\n",
    "    # Create the loss-function for the content-layers and -image.\n",
    "    loss_content = create_content_loss(session=session,\n",
    "                                       model=model,\n",
    "                                       content_image=content_image,\n",
    "                                       layer_ids=content_layer_ids)\n",
    "\n",
    "    # Create the loss-function for the style-layers and -image.\n",
    "    loss_style = create_style_loss(session=session,\n",
    "                                   model=model,\n",
    "                                   style_image=style_image,\n",
    "                                   layer_ids=style_layer_ids)    \n",
    "\n",
    "    # Create the loss-function for the denoising of the mixed-image.\n",
    "    loss_denoise = create_denoise_loss(model)\n",
    "    \n",
    "    # Create TensorFlow variables for adjusting the values of\n",
    "    # the loss-functions. This is explained below.\n",
    "    adj_content = tf.Variable(1e-10, name='adj_content')\n",
    "    adj_style = tf.Variable(1e-10, name='adj_style')\n",
    "    adj_denoise = tf.Variable(1e-10, name='adj_denoise')\n",
    "\n",
    "    # Initialize the adjustment values for the loss-functions.\n",
    "    session.run([adj_content.initializer,\n",
    "                 adj_style.initializer,\n",
    "                 adj_denoise.initializer])\n",
    "\n",
    "    # Create TensorFlow operations for updating the adjustment values.\n",
    "    # These are basically just the reciprocal values of the\n",
    "    # loss-functions, with a small value 1e-10 added to avoid the\n",
    "    # possibility of division by zero.\n",
    "    update_adj_content = adj_content.assign(1.0 / (loss_content + 1e-10))\n",
    "    update_adj_style = adj_style.assign(1.0 / (loss_style + 1e-10))\n",
    "    update_adj_denoise = adj_denoise.assign(1.0 / (loss_denoise + 1e-10))\n",
    "\n",
    "    # This is the weighted loss-function that we will minimize\n",
    "    # below in order to generate the mixed-image.\n",
    "    # Because we multiply the loss-values with their reciprocal\n",
    "    # adjustment values, we can use relative weights for the\n",
    "    # loss-functions that are easier to select, as they are\n",
    "    # independent of the exact choice of style- and content-layers.\n",
    "    loss_combined = weight_content * adj_content * loss_content + \\\n",
    "                    weight_style * adj_style * loss_style + \\\n",
    "                    weight_denoise * adj_denoise * loss_denoise\n",
    "\n",
    "    # Use TensorFlow to get the mathematical function for the\n",
    "    # gradient of the combined loss-function with regard to\n",
    "    # the input image.\n",
    "    gradient = tf.gradients(loss_combined, model.input)\n",
    "    \n",
    "    # List of tensors that we will run in each optimization iteration.\n",
    "    run_list = [gradient, update_adj_content, update_adj_style, \\\n",
    "                update_adj_denoise]\n",
    "\n",
    "    # The mixed-image is initialized with random noise.\n",
    "    # It is the same size as the content-image.f\n",
    "    mixed_image = np.random.rand(*content_image.shape) + 128\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        # Create a feed-dict with the mixed-image.\n",
    "        feed_dict = model.create_feed_dict(image=mixed_image)\n",
    "\n",
    "        # Use TensorFlow to calculate the value of the\n",
    "        # gradient, as well as updating the adjustment values.\n",
    "        grad, adj_content_val, adj_style_val, adj_denoise_val \\\n",
    "        = session.run(run_list, feed_dict=feed_dict)\n",
    "\n",
    "        # Reduce the dimensionality of the gradient.\n",
    "        grad = np.squeeze(grad)\n",
    "\n",
    "        # Scale the step-size according to the gradient-values.\n",
    "        step_size_scaled = step_size / (np.std(grad) + 1e-8)\n",
    "\n",
    "        # Update the image by following the gradient.\n",
    "        mixed_image -= grad * step_size_scaled\n",
    "\n",
    "        # Ensure the image has valid pixel-values between 0 and 255.\n",
    "        mixed_image = np.clip(mixed_image, 0.0, 255.0)\n",
    "\n",
    "        # Print a little progress-indicator.\n",
    "        print(\". \", end=\"\")\n",
    "\n",
    "        # Display status once every 10 iterations, and the last.\n",
    "        if (i % 10 == 0) or (i == num_iterations - 1):\n",
    "            print()\n",
    "            print(\"Iteration:\", i)\n",
    "\n",
    "            # Print adjustment weights for loss-functions.\n",
    "            msg = \"Weight Adj. for Content: {0:.2e}, Style: {1:.2e}, Denoise: {2:.2e}\"\n",
    "            print(msg.format(adj_content_val, adj_style_val, adj_denoise_val))\n",
    "\n",
    "            # Plot the content-, style- and mixed-images.\n",
    "            plot_images(content_image=content_image,\n",
    "                        style_image=style_image,\n",
    "                        mixed_image=mixed_image)\n",
    "            \n",
    "    print()\n",
    "    print(\"Final image:\")\n",
    "    plot_image_big(mixed_image)\n",
    "\n",
    "    # Close the TensorFlow session to release its resources.\n",
    "    session.close()\n",
    "    \n",
    "    # Return the mixed-image.\n",
    "    return mixed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voxel_2d\n",
      "(6, 128, 128, 3)\n",
      "(6, 128, 128, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAJCCAYAAAAoZAXMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPlow/lsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1115ab5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "voxel_filename = '3Dmodels/model.binvox'\n",
    "voxel = load_voxel(voxel_filename)\n",
    "face_maps, face_colors = voxel_to_2d(voxel, [1, 9, 25])\n",
    "plot_2d_faces(face_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_layer_ids = [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_filename = 'images/landscape.jpg'\n",
    "style_image = load_image(style_filename, max_size=voxel.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The VGG16-model has 13 convolutional layers.\n",
    "# This selects all those layers as the style-layers.\n",
    "# This is somewhat slow to optimize.\n",
    "style_layer_ids = np.arange(13)\n",
    "\n",
    "# You can also select a sub-set of the layers, e.g. like this:\n",
    "# style_layer_ids = [1, 2, 3, 4]\n",
    "print(face_maps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "'''\n",
    "Creating a single master grid of all views\n",
    "'''\n",
    "\n",
    "\n",
    "def make_grid(face):\n",
    "    facev = np.vstack((face[4], face[2], face[1]))\n",
    "\n",
    "    block = np.zeros(face[0].shape)\n",
    "    face1 = np.vstack((block, face[0], block))\n",
    "    face2 = np.vstack((face[4], face[2], face[1]))\n",
    "    face3 = np.vstack((block, face[3], block))\n",
    "    face4 = np.vstack((block, face[5], block))\n",
    "    faceMaster = np.hstack((face1, face2, face3, face4))\n",
    "    top = (faceMaster.shape[1] - faceMaster.shape[0]) // 2\n",
    "    bottom = (faceMaster.shape[1] - faceMaster.shape[0]) // 2\n",
    "    topArr = np.zeros((top, faceMaster.shape[1], face4.shape[2]))\n",
    "    bottomArr = np.zeros((bottom, faceMaster.shape[1], face4.shape[2]))\n",
    "    return np.vstack((topArr, faceMaster, bottomArr))\n",
    "\n",
    "fcolors = make_grid(face_colors)\n",
    "np.expand_dims(fcolors, axis=0)\n",
    "figNew = plt.figure()\n",
    "plt.imshow(fcolors)\n",
    "plt.show()\n",
    "\n",
    "fmaps = make_grid(face_maps)\n",
    "### 1.5, 10, 0.3\n",
    "fcolors = style_transfer(content_image=fcolors,\n",
    "                     style_image=style_image,\n",
    "                     content_layer_ids=content_layer_ids,\n",
    "                     style_layer_ids=style_layer_ids,\n",
    "                     weight_content=1.5,\n",
    "                     weight_style=10,\n",
    "                     weight_denoise=0.3,\n",
    "                     num_iterations=1,\n",
    "                     step_size=10.0)\n",
    "colors = generate_voxel_colors([fcolors], [fmaps], voxel.shape)\n",
    "plot_2d_faces([fcolors])\n",
    "plot_3d_voxel(voxel.transpose((2,0,1)), colors.transpose((2,0,1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
